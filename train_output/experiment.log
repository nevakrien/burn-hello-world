2025-12-03T00:43:23.316120Z  WARN wgpu_hal::vulkan::instance: Unable to find extension: VK_EXT_physical_device_drm
2025-12-03T00:43:23.349043Z  INFO cubecl_wgpu::runtime: Using adapter AdapterInfo { name: "NVIDIA GeForce RTX 4090", vendor: 4318, device: 9860, device_type: DiscreteGpu, driver: "NVIDIA", driver_info: "550.144.03", backend: Vulkan }
2025-12-03T00:43:23.440172Z  INFO cubecl_wgpu::runtime: Created wgpu compute server on device Device { inner: Core(CoreDevice { context: ContextWgpuCore { type: "Native" }, id: Id(0,1), error_sink: Mutex { data: ErrorSink }, features: Features { features_wgpu: FeaturesWGPU(SHADER_FLOAT32_ATOMIC | TEXTURE_FORMAT_16BIT_NORM | TEXTURE_ADAPTER_SPECIFIC_FORMAT_FEATURES | PIPELINE_STATISTICS_QUERY | TIMESTAMP_QUERY_INSIDE_ENCODERS | TIMESTAMP_QUERY_INSIDE_PASSES | TEXTURE_BINDING_ARRAY | BUFFER_BINDING_ARRAY | STORAGE_RESOURCE_BINDING_ARRAY | SAMPLED_TEXTURE_AND_STORAGE_BUFFER_ARRAY_NON_UNIFORM_INDEXING | STORAGE_TEXTURE_ARRAY_NON_UNIFORM_INDEXING | PARTIALLY_BOUND_BINDING_ARRAY | MULTI_DRAW_INDIRECT | MULTI_DRAW_INDIRECT_COUNT | PUSH_CONSTANTS | ADDRESS_MODE_CLAMP_TO_ZERO | ADDRESS_MODE_CLAMP_TO_BORDER | POLYGON_MODE_LINE | POLYGON_MODE_POINT | CONSERVATIVE_RASTERIZATION | VERTEX_WRITABLE_STORAGE | CLEAR_TEXTURE | SPIRV_SHADER_PASSTHROUGH | MULTIVIEW | TEXTURE_ATOMIC | TEXTURE_FORMAT_NV12 | EXPERIMENTAL_RAY_TRACING_ACCELERATION_STRUCTURE | EXPERIMENTAL_RAY_QUERY | SHADER_F64 | SHADER_I16 | SHADER_PRIMITIVE_INDEX | SHADER_EARLY_DEPTH_TEST | SHADER_INT64 | SUBGROUP | SUBGROUP_VERTEX | SUBGROUP_BARRIER | PIPELINE_CACHE | SHADER_INT64_ATOMIC_MIN_MAX | SHADER_INT64_ATOMIC_ALL_OPS | TEXTURE_INT64_ATOMIC | EXPERIMENTAL_MESH_SHADER | EXPERIMENTAL_RAY_HIT_VERTEX_RETURN | EXPERIMENTAL_MESH_SHADER_MULTIVIEW | EXTENDED_ACCELERATION_STRUCTURE_VERTEX_FORMATS), features_webgpu: FeaturesWebGPU(DEPTH_CLIP_CONTROL | DEPTH32FLOAT_STENCIL8 | TEXTURE_COMPRESSION_BC | TEXTURE_COMPRESSION_BC_SLICED_3D | TIMESTAMP_QUERY | INDIRECT_FIRST_INSTANCE | RG11B10UFLOAT_RENDERABLE | BGRA8UNORM_STORAGE | FLOAT32_FILTERABLE | DUAL_SOURCE_BLENDING | CLIP_DISTANCES) } }) } => AdapterInfo { name: "NVIDIA GeForce RTX 4090", vendor: 4318, device: 9860, device_type: DiscreteGpu, driver: "NVIDIA", driver_info: "550.144.03", backend: Vulkan }
2025-12-03T00:43:23.295665Z  INFO burn_train::learner::train_val: Fitting the model:
 Model {
  l1: Linear {d_input: 3, d_output: 128, bias: true, params: 512}
  l2: Linear {d_input: 128, d_output: 1, bias: true, params: 129}
  activation: Gelu
  params: 641
}
2025-12-03T00:43:23.457992Z  INFO burn_train::learner::strategies::single::epoch: Executing training step for epoch 1
2025-12-03T00:43:23.459346Z  INFO burn_train::learner::strategies::single::epoch: Iteration 1
2025-12-03T00:43:23.461333Z  INFO cubecl_runtime::tune::tune_cache: Load autotune cache ...
2025-12-03T00:43:23.461358Z  INFO cubecl_runtime::tune::tune_cache: Loaded 0 autotune cached entries
2025-12-03T00:43:23.461385Z  INFO cubecl_runtime::tune::tuner: Tuning FusedMatmulAutotuneKey - MatmulKey: MatmulAutotuneKey { definition: MatmulProblemDefinition { m: 4, n: 128, k: 4, lhs_pow2_factor: 0, rhs_pow2_factor: 3, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: General } }, NumOutBuffers: 2, NumOps: 8
2025-12-03T00:43:23.461677Z  INFO cubecl_runtime::tune::tune_cache: Load autotune cache ...
2025-12-03T00:43:23.461696Z  INFO cubecl_runtime::tune::tune_cache: Loaded 0 autotune cached entries
2025-12-03T00:43:23.461708Z  INFO cubecl_runtime::tune::tuner: Tuning MatmulAutotuneKey - Definition: MatmulProblemDefinition { m: 4, n: 128, k: 4, lhs_pow2_factor: 0, rhs_pow2_factor: 3, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, Analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: General }
2025-12-03T00:43:25.573775Z  INFO cubecl_runtime::tune::tuner: Tuning FusedMatmulAutotuneKey - MatmulKey: MatmulAutotuneKey { definition: MatmulProblemDefinition { m: 4, n: 1, k: 128, lhs_pow2_factor: 3, rhs_pow2_factor: 0, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: MatVec } }, NumOutBuffers: 8, NumOps: 16
2025-12-03T00:43:25.574020Z  INFO cubecl_runtime::tune::tuner: Tuning MatmulAutotuneKey - Definition: MatmulProblemDefinition { m: 4, n: 1, k: 128, lhs_pow2_factor: 3, rhs_pow2_factor: 0, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, Analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: MatVec }
2025-12-03T00:43:25.787128Z  INFO cubecl_runtime::tune::tune_cache: Load autotune cache ...
2025-12-03T00:43:25.787163Z  INFO cubecl_runtime::tune::tune_cache: Loaded 0 autotune cached entries
2025-12-03T00:43:25.787178Z  INFO cubecl_runtime::tune::tuner: Tuning ReduceAutotuneKey - ElemInput: Float(F32), ElemOutput: Float(F32), ElemAcc: Float(F32), PotentialLineSize: 1, AxisIsContiguous: true, ReduceAxisShape: 16, ReduceCount: 4
2025-12-03T00:43:25.912102Z  INFO cubecl_runtime::tune::tune_cache: Load autotune cache ...
2025-12-03T00:43:25.912137Z  INFO cubecl_runtime::tune::tune_cache: Loaded 0 autotune cached entries
2025-12-03T00:43:25.912152Z  INFO cubecl_runtime::tune::tuner: Tuning FusedReduceAutotuneKey - ReduceKey: ReduceAutotuneKey { elem_input: Float(F32), elem_output: Float(F32), elem_acc: Float(F32), potential_line_size: 1, axis_is_contiguous: true, reduce_axis_shape: 16, reduce_count: 4 }, FuseNumReads: 2, FuseNumWrites: 1, FuseNumOps: 4
2025-12-03T00:43:26.046209Z  INFO cubecl_runtime::tune::tuner: Tuning FusedReduceAutotuneKey - ReduceKey: ReduceAutotuneKey { elem_input: Float(F32), elem_output: Float(F32), elem_acc: Float(F32), potential_line_size: 4, axis_is_contiguous: false, reduce_axis_shape: 16, reduce_count: 1 }, FuseNumReads: 8, FuseNumWrites: 2, FuseNumOps: 32
2025-12-03T00:43:26.057114Z  INFO cubecl_runtime::tune::tuner: Tuning ReduceAutotuneKey - ElemInput: Float(F32), ElemOutput: Float(F32), ElemAcc: Float(F32), PotentialLineSize: 4, AxisIsContiguous: true, ReduceAxisShape: 16, ReduceCount: 1
2025-12-03T00:43:26.310676Z  INFO cubecl_runtime::tune::tuner: Tuning MatmulAutotuneKey - Definition: MatmulProblemDefinition { m: 4, n: 128, k: 1, lhs_pow2_factor: 0, rhs_pow2_factor: 3, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, Analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: OuterProduct }
2025-12-03T00:43:26.381646Z  INFO cubecl_runtime::tune::tuner: Tuning MatmulAutotuneKey - Definition: MatmulProblemDefinition { m: 128, n: 1, k: 4, lhs_pow2_factor: 3, rhs_pow2_factor: 0, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: MildlyPermuted { transposed: true, batch_swap: false }, matrix_layout_rhs: Contiguous }, Analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: MatVec }
2025-12-03T00:43:26.451643Z  INFO cubecl_runtime::tune::tuner: Tuning FusedReduceAutotuneKey - ReduceKey: ReduceAutotuneKey { elem_input: Float(F32), elem_output: Float(F32), elem_acc: Float(F32), potential_line_size: 4, axis_is_contiguous: false, reduce_axis_shape: 16, reduce_count: 256 }, FuseNumReads: 2, FuseNumWrites: 2, FuseNumOps: 16
2025-12-03T00:43:26.464116Z  INFO cubecl_runtime::tune::tuner: Tuning ReduceAutotuneKey - ElemInput: Float(F32), ElemOutput: Float(F32), ElemAcc: Float(F32), PotentialLineSize: 4, AxisIsContiguous: false, ReduceAxisShape: 16, ReduceCount: 256
2025-12-03T00:43:26.747138Z  INFO cubecl_runtime::tune::tuner: Tuning FusedMatmulAutotuneKey - MatmulKey: MatmulAutotuneKey { definition: MatmulProblemDefinition { m: 4, n: 128, k: 4, lhs_pow2_factor: 0, rhs_pow2_factor: 3, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: MildlyPermuted { transposed: true, batch_swap: false }, matrix_layout_rhs: Contiguous }, analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: General } }, NumOutBuffers: 4, NumOps: 16
2025-12-03T00:43:26.747344Z  INFO cubecl_runtime::tune::tuner: Tuning MatmulAutotuneKey - Definition: MatmulProblemDefinition { m: 4, n: 128, k: 4, lhs_pow2_factor: 0, rhs_pow2_factor: 3, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: MildlyPermuted { transposed: true, batch_swap: false }, matrix_layout_rhs: Contiguous }, Analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: General }
2025-12-03T00:43:28.752214Z  INFO burn_train::learner::strategies::single::epoch: Executing validation step for epoch 1
2025-12-03T00:43:28.818788Z  INFO cubecl_runtime::tune::tuner: Tuning FusedMatmulAutotuneKey - MatmulKey: MatmulAutotuneKey { definition: MatmulProblemDefinition { m: 2, n: 128, k: 4, lhs_pow2_factor: 0, rhs_pow2_factor: 3, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: General } }, NumOutBuffers: 1, NumOps: 8
2025-12-03T00:43:28.818993Z  INFO cubecl_runtime::tune::tuner: Tuning MatmulAutotuneKey - Definition: MatmulProblemDefinition { m: 2, n: 128, k: 4, lhs_pow2_factor: 0, rhs_pow2_factor: 3, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, Analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: General }
2025-12-03T00:43:29.138279Z  INFO cubecl_runtime::tune::tuner: Tuning FusedMatmulAutotuneKey - MatmulKey: MatmulAutotuneKey { definition: MatmulProblemDefinition { m: 2, n: 1, k: 128, lhs_pow2_factor: 3, rhs_pow2_factor: 0, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: MatVec } }, NumOutBuffers: 1, NumOps: 4
2025-12-03T00:43:29.138445Z  INFO cubecl_runtime::tune::tuner: Tuning MatmulAutotuneKey - Definition: MatmulProblemDefinition { m: 2, n: 1, k: 128, lhs_pow2_factor: 3, rhs_pow2_factor: 0, elem_lhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_rhs: MatmulElemType { elem: Float(F32), quantized: false }, elem_out: MatmulElemType { elem: Float(F32), quantized: false }, matrix_layout_lhs: Contiguous, matrix_layout_rhs: Contiguous }, Analysis: MatmulAutotuneAnalysis { scale_global: Small, kind: MatVec }
2025-12-03T00:43:29.198166Z  INFO cubecl_runtime::tune::tuner: Tuning FusedReduceAutotuneKey - ReduceKey: ReduceAutotuneKey { elem_input: Float(F32), elem_output: Float(F32), elem_acc: Float(F32), potential_line_size: 1, axis_is_contiguous: true, reduce_axis_shape: 16, reduce_count: 4 }, FuseNumReads: 2, FuseNumWrites: 2, FuseNumOps: 8
2025-12-03T00:43:29.320546Z  WARN burn_train::learner::early_stopping: Can't find metric for early stopping.
2025-12-03T00:43:29.320571Z  INFO burn_train::learner::strategies::single::epoch: Executing training step for epoch 2
2025-12-03T00:43:29.322248Z  INFO burn_train::learner::strategies::single::epoch: Iteration 1
2025-12-03T00:43:29.341045Z  INFO burn_train::learner::strategies::single::epoch: Executing validation step for epoch 2
2025-12-03T00:43:29.386313Z  WARN burn_train::learner::early_stopping: Can't find metric for early stopping.
2025-12-03T00:43:29.386336Z  INFO burn_train::learner::strategies::single::epoch: Executing training step for epoch 3
2025-12-03T00:43:29.388784Z  INFO burn_train::learner::strategies::single::epoch: Iteration 1
2025-12-03T00:43:29.396041Z  INFO burn_train::learner::strategies::single::epoch: Executing validation step for epoch 3
2025-12-03T00:43:29.415478Z  WARN burn_train::learner::early_stopping: Can't find metric for early stopping.
2025-12-03T00:43:29.415495Z  INFO burn_train::learner::strategies::single::epoch: Executing training step for epoch 4
2025-12-03T00:43:29.417796Z  INFO burn_train::learner::strategies::single::epoch: Iteration 1
2025-12-03T00:43:29.424888Z  INFO burn_train::learner::strategies::single::epoch: Executing validation step for epoch 4
2025-12-03T00:43:29.445858Z  WARN burn_train::learner::early_stopping: Can't find metric for early stopping.
